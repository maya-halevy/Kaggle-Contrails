{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "train_folder = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/train'\n",
        "validation_folder = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation'\n",
        "test_folder = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:32.861887Z",
          "iopub.execute_input": "2023-07-06T17:57:32.862157Z",
          "iopub.status.idle": "2023-07-06T17:57:32.875695Z",
          "shell.execute_reply.started": "2023-07-06T17:57:32.862132Z",
          "shell.execute_reply": "2023-07-06T17:57:32.874240Z"
        },
        "trusted": true,
        "id": "QB_8hvYHHzZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "def load_and_process_file(file_path):\n",
        "    data = np.load(file_path)\n",
        "    img = data[..., 4]  # Getting the fifth slice across the third dimension\n",
        "    min_val = np.min(img)\n",
        "    max_val = np.max(img)\n",
        "    normalized_data = ((img - min_val) / (max_val - min_val)) # Normalizing the data to be in range [0, 1]\n",
        "    # sobel_x = cv2.Sobel(normalized_data, cv2.CV_64F, 1, 0)\n",
        "    # sobel_y = cv2.Sobel(normalized_data, cv2.CV_64F, 0, 1)\n",
        "    # sobel_mag = np.sqrt(np.square(sobel_x) + np.square(sobel_y))\n",
        "    # clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
        "    # clahe_image = clahe.apply(normalized_data)\n",
        "    return normalized_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:32.904718Z",
          "iopub.execute_input": "2023-07-06T17:57:32.905575Z",
          "iopub.status.idle": "2023-07-06T17:57:42.584402Z",
          "shell.execute_reply.started": "2023-07-06T17:57:32.905544Z",
          "shell.execute_reply": "2023-07-06T17:57:42.583301Z"
        },
        "trusted": true,
        "id": "WDVLLQiuHzZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, base_dir, batch_size=32):\n",
        "        self.base_dir = base_dir\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # List all directories in the base directory\n",
        "        self.image_dirs = [os.path.join(base_dir, x) for x in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, x))]\n",
        "        self.indices = np.arange(len(self.image_dirs))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_dirs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Select self.batch_size directories\n",
        "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_dirs = [self.image_dirs[i] for i in batch_indices]\n",
        "\n",
        "        # Prepare empty arrays for our batch\n",
        "        images = np.empty((self.batch_size, 256, 256, 3))\n",
        "        labels = np.empty((self.batch_size, 256, 256, 1))\n",
        "\n",
        "        for i, dir_path in enumerate(batch_dirs):\n",
        "            # Load each of the three bands, process it, and stack them\n",
        "            band_08 = load_and_process_file(os.path.join(dir_path, 'band_08.npy'))\n",
        "            band_12 = load_and_process_file(os.path.join(dir_path, 'band_12.npy'))\n",
        "            band_16 = load_and_process_file(os.path.join(dir_path, 'band_16.npy'))\n",
        "            images[i] = np.stack([band_08, band_12, band_16], axis=-1)\n",
        "\n",
        "            # Load the label and add it to our labels array\n",
        "            labels[i] = np.load(os.path.join(dir_path, 'human_pixel_masks.npy'))\n",
        "\n",
        "        return images, labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:42.586565Z",
          "iopub.execute_input": "2023-07-06T17:57:42.587213Z",
          "iopub.status.idle": "2023-07-06T17:57:42.599288Z",
          "shell.execute_reply.started": "2023-07-06T17:57:42.587184Z",
          "shell.execute_reply": "2023-07-06T17:57:42.598275Z"
        },
        "trusted": true,
        "id": "LjIbaQIdHzZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "\n",
        "# source\n",
        "# https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/TensorFlow/efficientnetb0_unet.py\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(inputs, skip, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_effienet_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained Encoder \"\"\"\n",
        "    encoder = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    s1 = encoder.get_layer(\"input_1\").output                      ## 256\n",
        "    s2 = encoder.get_layer(\"block2a_expand_activation\").output    ## 128\n",
        "    s3 = encoder.get_layer(\"block3a_expand_activation\").output    ## 64\n",
        "    s4 = encoder.get_layer(\"block4a_expand_activation\").output    ## 32\n",
        "\n",
        "    \"\"\" Bottleneck \"\"\"\n",
        "    b1 = encoder.get_layer(\"block6a_expand_activation\").output    ## 16\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                               ## 32\n",
        "    d2 = decoder_block(d1, s3, 256)                               ## 64\n",
        "    d3 = decoder_block(d2, s2, 128)                               ## 128\n",
        "    d4 = decoder_block(d3, s1, 64)                                ## 256\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"EfficientNetB0_UNET\")\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:42.601040Z",
          "iopub.execute_input": "2023-07-06T17:57:42.601647Z",
          "iopub.status.idle": "2023-07-06T17:57:42.616141Z",
          "shell.execute_reply.started": "2023-07-06T17:57:42.601615Z",
          "shell.execute_reply": "2023-07-06T17:57:42.615227Z"
        },
        "trusted": true,
        "id": "Co7Ur6TMHzZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:42.629777Z",
          "iopub.execute_input": "2023-07-06T17:57:42.630186Z",
          "iopub.status.idle": "2023-07-06T17:57:42.639630Z",
          "shell.execute_reply.started": "2023-07-06T17:57:42.630156Z",
          "shell.execute_reply": "2023-07-06T17:57:42.638725Z"
        },
        "trusted": true,
        "id": "JBcdpflLHzZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "model = build_effienet_unet(input_shape)\n",
        "\n",
        "train_gen = DataGenerator(train_folder)\n",
        "val_gen = DataGenerator(validation_folder)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss=dice_coef_loss, metrics=[jacard_coef, dice_coef])\n",
        "\n",
        "# Define the filepath format for saving the model weights\n",
        "checkpoint_path = \"/kaggle/working/weights.h5\"\n",
        "\n",
        "# Define a custom callback to print validation metrics\n",
        "class ValidationMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs['val_loss']\n",
        "        val_jacard_coef = logs['val_jacard_coef']\n",
        "        val_dice_coef = logs['val_dice_coef']\n",
        "        print(f'\\nEpoch {epoch + 1}: val_loss = {val_loss:.4f}, val_jacard_coef = {val_jacard_coef:.4f}, val_dice_coef = {val_dice_coef:.4f}\\n')\n",
        "\n",
        "# Create an instance of the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
        "\n",
        "# Train the model with the checkpoint and custom validation metrics callbacks\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=3, steps_per_epoch=312,\n",
        "          validation_steps=58, callbacks=[checkpoint_callback, ValidationMetricsCallback()])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:42.640956Z",
          "iopub.execute_input": "2023-07-06T17:57:42.641813Z",
          "iopub.status.idle": "2023-07-06T17:57:43.465526Z",
          "shell.execute_reply.started": "2023-07-06T17:57:42.641761Z",
          "shell.execute_reply": "2023-07-06T17:57:43.463897Z"
        },
        "trusted": true,
        "id": "ADxVUa4fHzZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get the next batch of validation data\n",
        "images, true_masks = next(iter(val_gen))\n",
        "\n",
        "# Predict masks on the images\n",
        "predicted_masks = model.predict(images)\n",
        "\n",
        "# Rescale the masks back to 0-255 range\n",
        "# predicted_masks = (predicted_masks * 255).astype(np.uint8)\n",
        "\n",
        "# Iterate over the images, true masks, and predicted masks and plot them\n",
        "for i in range(len(images)):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Plot image\n",
        "    axs[0].imshow(images[i])\n",
        "    axs[0].set_title('Image')\n",
        "\n",
        "    # Plot true mask\n",
        "    axs[1].imshow(true_masks[i].squeeze(), cmap='gray')\n",
        "    axs[1].set_title('True Mask')\n",
        "\n",
        "    # Plot predicted mask\n",
        "    axs[2].imshow(predicted_masks[i].squeeze(), cmap='gray')\n",
        "    axs[2].set_title('Predicted Mask')\n",
        "\n",
        "    # Hide axes\n",
        "    axs[0].axis('off')\n",
        "    axs[1].axis('off')\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-06T17:57:43.470876Z",
          "iopub.status.idle": "2023-07-06T17:57:43.471667Z",
          "shell.execute_reply.started": "2023-07-06T17:57:43.471419Z",
          "shell.execute_reply": "2023-07-06T17:57:43.471442Z"
        },
        "trusted": true,
        "id": "bqZikXp5HzZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}